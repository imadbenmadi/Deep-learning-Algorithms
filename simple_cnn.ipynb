{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10be9525",
   "metadata": {},
   "source": [
    "# Developing a CNN for CIFAR-10 with PyTorch\n",
    "\n",
    "This notebook guides you through the process of building, training, and evaluating a Convolutional Neural Network (CNN) on the CIFAR-10 dataset using PyTorch. CIFAR-10 is a standard dataset consisting of 60,000 32x32 color images in 10 different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797488c3",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "We'll start by importing PyTorch and other necessary libraries for working with CNNs and the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625517f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f01d8",
   "metadata": {},
   "source": [
    "## Load and Prepare CIFAR Dataset\n",
    "\n",
    "We'll download and load the CIFAR-10 dataset using PyTorch's torchvision.datasets module. The CIFAR-10 dataset contains 50,000 training images and 10,000 test images across 10 classes:\n",
    "- Airplane\n",
    "- Automobile\n",
    "- Bird\n",
    "- Cat\n",
    "- Deer\n",
    "- Dog\n",
    "- Frog\n",
    "- Horse\n",
    "- Ship\n",
    "- Truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store the dataset\n",
    "data_dir = './data'\n",
    "\n",
    "# Download and load CIFAR-10 dataset\n",
    "print(\"Downloading CIFAR-10 dataset...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5252ec",
   "metadata": {},
   "source": [
    "## Data Transformation and Augmentation\n",
    "\n",
    "Data transformations and augmentations are crucial for improving model generalization. We'll apply:\n",
    "1. Normalization: Scale pixel values to have zero mean and unit variance\n",
    "2. Augmentations for training: Random crops and horizontal flips to increase diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5750ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for training data (with augmentation)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# Define transforms for test data (no augmentation, only normalization)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=data_dir, train=True, download=True, transform=transform_train\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=data_dir, train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "# Define class names for later visualization\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af77c42",
   "metadata": {},
   "source": [
    "## Create Data Loaders\n",
    "\n",
    "PyTorch's DataLoader class provides an efficient way to batch, shuffle, and load data in parallel. We'll set up DataLoaders for both training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ee3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Let's see the shape of our data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(f\"Batch shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Display some sample images\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    img = images[i].numpy().transpose((1, 2, 0))\n",
    "    # Unnormalize\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "    std = np.array([0.2470, 0.2435, 0.2616])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(classes[labels[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1689a3e",
   "metadata": {},
   "source": [
    "## Define CNN Architecture\n",
    "\n",
    "Now we'll define our CNN architecture using PyTorch's nn.Module. Our model consists of:\n",
    "- Multiple convolutional layers with batch normalization\n",
    "- MaxPooling layers for dimensionality reduction\n",
    "- ReLU activations for non-linearity\n",
    "- Dropout for regularization\n",
    "- Fully connected layers for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10_CNN, self).__init__()\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Fourth convolutional block\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 512)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Second block\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Third block\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Fourth block\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        \n",
    "        # Fully connected layers with dropout\n",
    "        x = self.dropout(F.relu(self.bn5(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the model and move it to the device\n",
    "model = CIFAR10_CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2c8d6",
   "metadata": {},
   "source": [
    "## Set Up Training Components\n",
    "\n",
    "Here we'll define the necessary components for training our CNN model:\n",
    "1. Loss function: Cross-Entropy Loss, suitable for multi-class classification\n",
    "2. Optimizer: Adam optimizer for efficient gradient-based optimization\n",
    "3. Learning rate scheduler: To reduce the learning rate during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2628100",
   "metadata": {},
   "source": [
    "## Train the CNN Model\n",
    "\n",
    "Now we'll implement the training loop. In each epoch, we:\n",
    "1. Iterate through batches of training data\n",
    "2. Forward pass through the model\n",
    "3. Calculate the loss\n",
    "4. Backward pass to compute gradients\n",
    "5. Update model parameters\n",
    "6. Track metrics like accuracy and loss\n",
    "\n",
    "We'll also periodically evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ed132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs to train\n",
    "epochs = 20\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, trainloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for inputs, labels in tqdm(trainloader, desc=\"Training\"):\n",
    "        # Move inputs and labels to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = calculate_accuracy(outputs, labels)\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        running_acc += acc\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epoch_acc = running_acc / len(trainloader)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, testloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(testloader, desc=\"Testing\"):\n",
    "            # Move inputs and labels to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            acc = calculate_accuracy(outputs, labels)\n",
    "            \n",
    "            # Update statistics\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc\n",
    "    \n",
    "    epoch_loss = running_loss / len(testloader)\n",
    "    epoch_acc = running_acc / len(testloader)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Training loop\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_acc = train_epoch(model, trainloader, optimizer, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc = evaluate(model, testloader, criterion, device)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "    \n",
    "    # Save the model if it's the best so far\n",
    "    if test_acc == max(test_accuracies):\n",
    "        torch.save(model.state_dict(), \"cifar10_cnn_best.pt\")\n",
    "        print(\"Best model saved!\")\n",
    "\n",
    "# Calculate training time\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"\\nTraining completed in {training_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582c135",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Now that we've trained the model, let's evaluate its performance on the test set and look at various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"cifar10_cnn_best.pt\"))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "def get_all_preds(model, loader, device):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "# Get predictions\n",
    "y_pred, y_true = get_all_preds(model, testloader, device)\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add numbers to the cells\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbe942",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's visualize the training progress and examine some predictions on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize some predictions\n",
    "def visualize_predictions(model, testloader, device, classes, n=10):\n",
    "    # Get a batch of test images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Make predictions\n",
    "    images_device = images[:n].to(device)\n",
    "    outputs = model(images_device)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Display images along with predictions\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    \n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        \n",
    "        # Display image\n",
    "        img = images[i].numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "        std = np.array([0.2470, 0.2435, 0.2616])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        \n",
    "        # Display prediction and ground truth\n",
    "        color = 'green' if predicted[i] == labels[i] else 'red'\n",
    "        plt.title(f\"Pred: {classes[predicted[i]]}\\nTrue: {classes[labels[i]]}\", \n",
    "                  color=color, fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, testloader, device, classes, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3823e66",
   "metadata": {},
   "source": [
    "## Save and Load the Model\n",
    "\n",
    "Finally, let's demonstrate how to save and load our trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c951aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model was already saved during training\n",
    "# Here's how to load it and use it for inference\n",
    "\n",
    "# Define a function to save the model\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary and architecture info\"\"\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_architecture': 'CIFAR10_CNN'\n",
    "    }, filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "# Define a function to load the model\n",
    "def load_model(filepath, device):\n",
    "    \"\"\"Load a model from a checkpoint file\"\"\"\n",
    "    # Load the saved data\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    \n",
    "    # Create a new instance of the model architecture\n",
    "    model = CIFAR10_CNN().to(device)\n",
    "    \n",
    "    # Load the state dictionary\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"Loaded model from {filepath}\")\n",
    "    return model\n",
    "\n",
    "# Example of saving the model\n",
    "save_model(model, \"cifar10_cnn_final.pt\")\n",
    "\n",
    "# Example of loading the model\n",
    "loaded_model = load_model(\"cifar10_cnn_final.pt\", device)\n",
    "\n",
    "# Quick test to ensure the loaded model works\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get one batch of test data\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Make predictions\n",
    "    outputs = loaded_model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Calculate accuracy for this batch\n",
    "    accuracy = (predicted == labels).sum().item() / len(labels)\n",
    "    print(f\"Loaded model accuracy on a batch: {accuracy:.4f}\")\n",
    "\n",
    "# Example of using the model for inference on a single image\n",
    "def predict_single_image(model, image_tensor, device, classes):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Add batch dimension and send to device\n",
    "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        # Get probability distribution\n",
    "        probabilities = F.softmax(output, dim=1)[0]\n",
    "        \n",
    "        return {\n",
    "            'class': classes[predicted.item()],\n",
    "            'class_index': predicted.item(),\n",
    "            'probabilities': {classes[i]: float(probabilities[i]) for i in range(len(classes))}\n",
    "        }\n",
    "\n",
    "# Get a test image\n",
    "test_image, test_label = testset[0]\n",
    "result = predict_single_image(loaded_model, test_image, device, classes)\n",
    "\n",
    "print(f\"True class: {classes[test_label]}\")\n",
    "print(f\"Predicted class: {result['class']}\")\n",
    "print(\"Probabilities:\")\n",
    "for class_name, prob in result['probabilities'].items():\n",
    "    print(f\"  {class_name}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda015f8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've:\n",
    "1. Loaded and prepared the CIFAR-10 dataset\n",
    "2. Applied data transformations and augmentations\n",
    "3. Built a CNN architecture using PyTorch\n",
    "4. Trained the model with optimization techniques\n",
    "5. Evaluated the model's performance\n",
    "6. Visualized results and predictions\n",
    "7. Saved and loaded the model for future use\n",
    "\n",
    "The techniques demonstrated here can be applied to other image classification tasks by adapting the architecture, hyperparameters, and data preprocessing steps to suit the specific dataset and problem."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
